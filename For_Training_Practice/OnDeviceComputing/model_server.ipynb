{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef9c7c-1c01-4bb8-948f-8683e027db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (1) Mobius 관련 설정\n",
    "# --------------------------------------------------------------------------------\n",
    "#수업용 데이터 정보\n",
    "MOBIUS_BASE_URL = \"https://onem2m.iotcoss.ac.kr/Mobius/\"\n",
    "MOBIUS_AE_NAME  = \"OnDevice AE name\"\n",
    "\n",
    "\n",
    "MOBIUS_MODEL_REPOSITORY_CNT_NAME  = \"model_repository\"\n",
    "\n",
    "MOBIUS_BASE_AE_URL = os.path.join(MOBIUS_BASE_URL, MOBIUS_AE_NAME)\n",
    "\n",
    "#학생이 만든 AE 정보, #학번이라 표기된 곳은 본인의 학번 기입 \n",
    "MOBIUS_STUDENT_AE_NAME  = \"OC-practice-학번\" \n",
    "MOBIUS_STUDENT_INFERENCING_RESULT_CNT_NAME= \"inferencing_result\"\n",
    "MOBIUS_STUDENT_SENSOR_DATA_CNT_NAME       = \"sensor_data\"\n",
    "MOBIUS_STUDENT_AE_URL = os.path.join(MOBIUS_BASE_URL, MOBIUS_STUDENT_AE_NAME)\n",
    "\n",
    "# 학생이 만든 AE에 추론 결과 업로드 시 사용될 헤더 (CIN 생성)\n",
    "HEADERS_CIN = {\n",
    "    'Accept': 'application/json',\n",
    "    'X-M2M-RI': '12345',\n",
    "    'X-M2M-Origin': 'SOriginOC학번',\n",
    "    'Content-Type': 'application/vnd.onem2m-res+json; ty=4',\n",
    "    'X-API-KEY':         'your-api-key',\n",
    "    'X-AUTH-CUSTOM-LECTURE': 'lecture-id',\n",
    "    'X-AUTH-CUSTOM-CREATOR': 'your-creator-id'\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (2) Mobius 연동 함수\n",
    "# --------------------------------------------------------------------------------\n",
    "def http_get(url, params=None, headers=None, iotPlatform=False):\n",
    "    \"\"\"\n",
    "    - iotPlatform=True이면 OneM2M 관련 헤더 자동 적용\n",
    "    - GET 요청 후 JSON 반환\n",
    "    \"\"\"\n",
    "    if iotPlatform:\n",
    "        headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'X-M2M-RI': '12345',\n",
    "            'X-M2M-Origin': 'SOrigin',\n",
    "            'X-API-KEY':         'your-api-key',\n",
    "            'X-AUTH-CUSTOM-LECTURE': 'lecture-id',\n",
    "            'X-AUTH-CUSTOM-CREATOR': 'your-creator-id'\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[Mobius Error] GET {url} : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def all_cin_get_uri(path, max_retries=10):\n",
    "    \"\"\"\n",
    "    주어진 컨테이너 경로에서 모든 콘텐츠 인스턴스(CIN) URI를 얻어\n",
    "    각각을 GET하여 'con' 필드를 모아 리스트로 반환한다.\n",
    "    \"\"\"\n",
    "    path = path + '?fu=1&ty=4'  # 모든 CIN(ResourceType=4) 조회 쿼리\n",
    "    parsed_path = urlparse(path)\n",
    "    base_path   = f\"{parsed_path.scheme}://{parsed_path.netloc}/\"\n",
    "    resource_path = path.split('?')[0]\n",
    "\n",
    "    con_list = []\n",
    "    print(f\"  [DISCOVERY] 대상 경로: {resource_path}\")\n",
    "    all_uri  = http_get(path, iotPlatform=True)\n",
    "    if not all_uri:\n",
    "        print(f\"  [DISCOVERY] URI 목록을 가져오지 못했습니다: {resource_path}\")\n",
    "        return con_list  # 에러 시 빈 리스트 반환\n",
    "\n",
    "    uri_list = all_uri.get(\"m2m:uril\", [])\n",
    "    total_uris = len(uri_list)\n",
    "    print(f\"  [DISCOVERY] 발견된 CIN URI: {total_uris}건\")\n",
    "    if not uri_list:\n",
    "        return con_list\n",
    "\n",
    "    # 각 URI에 대해 실제 데이터 GET\n",
    "    for idx, uri in enumerate(uri_list, start=1):\n",
    "        print(f\"    [FETCH {idx}/{total_uris}] {uri}\")\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            cin = http_get(base_path + uri, iotPlatform=True)\n",
    "            if cin is not None:\n",
    "                con_list.append(cin[\"m2m:cin\"][\"con\"])\n",
    "                break\n",
    "            else:\n",
    "                retries += 1\n",
    "                print(f\"[Retry {retries}] for URL: {base_path + uri}\")\n",
    "\n",
    "        if retries == max_retries:\n",
    "            print(f\"[FAIL] Data not fetched after {max_retries} attempts for URL: {base_path + uri}\")\n",
    "\n",
    "    return con_list\n",
    "\n",
    "\n",
    "def decode_model(base64_str, save_path=\"./mnist_cnn.pth\"):\n",
    "    \"\"\"\n",
    "    - Base64 문자열을 받아 .pth 모델 파일로 저장\n",
    "    - 저장 경로 반환\n",
    "    \"\"\"\n",
    "    decoded_bytes = base64.b64decode(base64_str)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(decoded_bytes)\n",
    "    return save_path\n",
    "\n",
    "\n",
    "def upload_data(sensor_name, data, base_url):\n",
    "    \"\"\"\n",
    "    base_url 아래 sensor_name 컨테이너에 'data'를 콘텐츠 인스턴스(CIN) 형태로 업로드한다.\n",
    "    \"\"\"\n",
    "    url  = f\"{base_url}/{sensor_name}\"\n",
    "    body = {\n",
    "        \"m2m:cin\": {\n",
    "            \"con\": data\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=HEADERS_CIN, json=body)\n",
    "    if response.status_code in [200, 201]:\n",
    "        print(f\"[OK] Data uploaded to '{sensor_name}' at {base_url}.\")\n",
    "    else:\n",
    "        print(f\"[FAIL] Upload data to '{sensor_name}' at {base_url}: {response.text}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (3) 모델 정의 (예: MNISTCNN)\n",
    "# --------------------------------------------------------------------------------\n",
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self, output_size=10):\n",
    "        super(MNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1   = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2   = nn.Linear(128, output_size)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.relu  = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (4) 이미지 전처리 함수 (Base64 → 텐서)\n",
    "# --------------------------------------------------------------------------------\n",
    "def preprocess_image_bytes(b64_str):\n",
    "    \"\"\"\n",
    "    - Base64 문자열(b64_str)을 받아,\n",
    "      1) base64 디코딩 → 2) BytesIO → 3) PIL.Image\n",
    "      4) 28×28 흑백으로 변환 → 5) NumPy → 6) PyTorch 텐서\n",
    "    - 최종 shape: (1, 1, 28, 28)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1) base64 → bytes\n",
    "        img_bytes = base64.b64decode(b64_str)\n",
    "        # 2) BytesIO → PIL\n",
    "        pil_image = Image.open(BytesIO(img_bytes)).convert(\"L\")\n",
    "        # 3) 28×28 리사이즈 (MNIST)\n",
    "        pil_image = pil_image.resize((28, 28))\n",
    "        # 4) [0~255] 범위 유지 (정규화 제거)\n",
    "        arr = np.array(pil_image).astype(np.float32)\n",
    "        # 5) (H, W) → (1, 1, H, W)\n",
    "        tensor = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)  # [1, 1, 28, 28]\n",
    "        return tensor\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] preprocess_image_bytes failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (5) 메인: 소켓 서버 + Mobius 모델 로드\n",
    "# --------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 1) Mobius에서 최신 모델 가져오기\n",
    "    model_repo_path = f\"{MOBIUS_BASE_AE_URL}/{MOBIUS_MODEL_REPOSITORY_CNT_NAME}\"\n",
    "    con_list = all_cin_get_uri(model_repo_path)\n",
    "    if not con_list:\n",
    "        print(\"[Error] No model data in Mobius.\")\n",
    "        exit(1)\n",
    "\n",
    "    # 1.1) 가장 최근에 올라온 모델(con_list[-1]) 사용\n",
    "    latest_model_data = con_list[-1]  # {\"metadata\": {...}, \"model_file\": \"...(base64)...\" }\n",
    "    base64_model_str  = latest_model_data[\"model_file\"]\n",
    "    metadata          = latest_model_data[\"metadata\"]\n",
    "\n",
    "    # 1.2) 디코딩 → 로컬에 저장\n",
    "    model_path = decode_model(base64_model_str, save_path=\"./mnist_cnn.pth\")\n",
    "\n",
    "    # 1.3) 모델 로드\n",
    "    model = MNISTCNN(output_size=10)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'), weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"[MODEL SERVER] Loaded model: {metadata['model_name']} (version {metadata['version']})\")\n",
    "\n",
    "    # 2) 소켓 서버 준비\n",
    "    host = '127.0.0.1'\n",
    "    port = 5000\n",
    "\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(1)\n",
    "    print(f\"[MODEL SERVER] Listening on {host}:{port}\")\n",
    "\n",
    "    # 3) 연결 대기 → 연결 시 데이터 수신/추론\n",
    "    while True:\n",
    "        conn, addr = server_socket.accept()\n",
    "        print(f\"[MODEL SERVER] Connected by {addr}\")\n",
    "\n",
    "        while True:\n",
    "            # 4) 센서(또는 클라이언트)로부터 메시지 수신 (JSON string)\n",
    "            data = conn.recv(4096).decode('utf-8')\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                msg = json.loads(data)\n",
    "            except Exception as e:\n",
    "                print(\"[MODEL SERVER] JSON decode error:\", e)\n",
    "                break\n",
    "\n",
    "            # (4.1) 센서 데이터를 Mobius의 sensor_data 컨테이너에 업로드\n",
    "            sensor_data_con = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"raw_base64\": msg.get(\"image_data\", \"\"),  # 원한다면 Base64를 그대로 보관\n",
    "            }\n",
    "            upload_data(MOBIUS_STUDENT_SENSOR_DATA_CNT_NAME, sensor_data_con, MOBIUS_STUDENT_AE_URL)\n",
    "\n",
    "            # (4.2) 추론\n",
    "            b64_str    = msg.get(\"image_data\", \"\")\n",
    "            image_tensor = preprocess_image_bytes(b64_str)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image_tensor)\n",
    "                pred   = torch.argmax(output).item()\n",
    "\n",
    "            # (4.3) 추론 결과\n",
    "            result_data = {\n",
    "                \"prediction\": pred,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "            # (4.4) 추론 결과를 Mobius의 inferencing_result 컨테이너에 업로드\n",
    "            upload_data(MOBIUS_STUDENT_INFERENCING_RESULT_CNT_NAME, result_data, MOBIUS_STUDENT_AE_URL)\n",
    "\n",
    "            # (4.5) 응답(추론 결과) 소켓으로 전송\n",
    "            print(f\"[MODEL SERVER] Prediction: {pred}\")\n",
    "            result_json = json.dumps(result_data)\n",
    "            conn.sendall(result_json.encode('utf-8'))\n",
    "\n",
    "        # 연결 종료\n",
    "        conn.close()\n",
    "        print(f\"[MODEL SERVER] Connection closed by {addr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIoT_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

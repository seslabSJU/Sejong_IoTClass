{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import base64\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from urllib.parse import urlparse\n",
        "from datetime import datetime\n",
        "# --------------------------------------------------------------------------------\n",
        "# (1) Mobius 플랫폼 설정\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "# 수업용 데이터 AE (모델 + 이미지 데이터가 있는 곳)\n",
        "MOBIUS_BASE_URL = \"https://onem2m.iotcoss.ac.kr/Mobius/\"\n",
        "MOBIUS_DATA_AE_NAME = \"AIoT-HW\"  # 수업용 AE (수정 X)\n",
        "\n",
        "MOBIUS_IMAGE_DATA_CNT_NAME = \"image_data\"           # 이미지 데이터 컨테이너\n",
        "MOBIUS_MODEL_REPOSITORY_CNT_NAME = \"model_repository\"  # 모델 저장 컨테이너\n",
        "\n",
        "MOBIUS_DATA_AE_URL = os.path.join(MOBIUS_BASE_URL, MOBIUS_DATA_AE_NAME)\n",
        "\n",
        "# 학생용 AE (추론 결과를 업로드할 곳) - 본인 정보로 수정!\n",
        "MOBIUS_STUDENT_AE_NAME = \"AIoT-HW-학번\"  # ← 본인 학번 이어붙여 생성\n",
        "MOBIUS_STUDENT_INFERENCING_RESULT_CNT_NAME = \"inferencing_result\"\n",
        "MOBIUS_STUDENT_AE_URL = os.path.join(MOBIUS_BASE_URL, MOBIUS_STUDENT_AE_NAME)\n",
        "#실습 실행 이전에 개인용 AE와 추론 결과 저장용 CNT가 반드시 만들어져 있어야 함!\n",
        "\n",
        "# GET 요청 헤더 (수업용 데이터 조회)\n",
        "HEADERS_GET = {\n",
        "    'Accept': 'application/json',\n",
        "    'X-M2M-RI': '12345',\n",
        "    'X-M2M-Origin': 'SOrigin',\n",
        "    'X-API-KEY': 'your-api-key',              # ← 본인 API 키\n",
        "    'X-AUTH-CUSTOM-LECTURE': 'lecture-id',    # ← 수업 ID\n",
        "    'X-AUTH-CUSTOM-CREATOR': 'your-creator-id' # ← 본인 ID\n",
        "}\n",
        "\n",
        "# POST 요청 헤더 (추론 결과 업로드)\n",
        "HEADERS_CIN = {\n",
        "    'Accept': 'application/json',\n",
        "    'X-M2M-RI': '12345',\n",
        "    'X-M2M-Origin': 'SOriginHW학번',          # ← 본인 Originator, 학번 입력\n",
        "    'Content-Type': 'application/vnd.onem2m-res+json; ty=4',\n",
        "    'X-API-KEY': 'your-api-key',              # ← 본인 API 키\n",
        "    'X-AUTH-CUSTOM-LECTURE': 'lecture-id',    # ← 수업 ID\n",
        "    'X-AUTH-CUSTOM-CREATOR': 'your-creator-id' # ← 본인 ID\n",
        "}\n",
        "# --------------------------------------------------------------------------------\n",
        "# (2) Mobius 연동 함수\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "def http_get(url, params=None, headers=None, iotPlatform=None):\n",
        "    \"\"\"\n",
        "    주어진 URL에 GET 요청을 보내고, 결과를 JSON(dict)로 반환한다.\n",
        "    iotPlatform=True이면 OneM2M용 기본 헤더가 적용된다.\n",
        "    \"\"\"\n",
        "    if iotPlatform:\n",
        "        headers = {\n",
        "            'Accept':       'application/json',\n",
        "            'X-M2M-RI':     '12345',\n",
        "            'X-M2M-Origin': 'SOrigin',\n",
        "            'X-API-KEY': 'your-api-key',             \n",
        "            'X-AUTH-CUSTOM-LECTURE': 'lecture-id',    \n",
        "            'X-AUTH-CUSTOM-CREATOR': 'your-creator-id' \n",
        "        }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        return json.loads(response.text)\n",
        "    \n",
        "    except requests.ConnectTimeout:\n",
        "        print(f\"[Error] Connection timed out for URL: {url}\")\n",
        "        return None\n",
        "\n",
        "    except requests.HTTPError as http_err:\n",
        "        print(f\"[Error] HTTP error occurred for URL {url}: {http_err}\")\n",
        "        return None\n",
        "\n",
        "    except Exception as err:\n",
        "        print(f\"[Error] An error occurred for URL {url}: {err}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def all_cin_get_uri(path, max_retries=10):\n",
        "    \"\"\"\n",
        "    주어진 컨테이너 경로에서 모든 콘텐츠 인스턴스(CIN) URI를 얻어\n",
        "    각각을 GET하여 'con' 필드를 모아 리스트로 반환한다.\n",
        "    \"\"\"\n",
        "    path = path + '?fu=1&ty=4'  # 모든 CIN(ResourceType=4) 조회 쿼리\n",
        "    parsed_path = urlparse(path)\n",
        "    base_path   = f\"{parsed_path.scheme}://{parsed_path.netloc}/\"\n",
        "    resource_path = path.split('?')[0]\n",
        "\n",
        "    con_list = []\n",
        "    print(f\"  [DISCOVERY] 대상 경로: {resource_path}\")\n",
        "    all_uri  = http_get(path, iotPlatform=True)\n",
        "    if not all_uri:\n",
        "        print(f\"  [DISCOVERY] URI 목록을 가져오지 못했습니다: {resource_path}\")\n",
        "        return con_list  # 에러 시 빈 리스트 반환\n",
        "\n",
        "    uri_list = all_uri.get(\"m2m:uril\", [])\n",
        "    total_uris = len(uri_list)\n",
        "    print(f\"  [DISCOVERY] 발견된 CIN URI: {total_uris}건\")\n",
        "    if not uri_list:\n",
        "        return con_list\n",
        "\n",
        "    # 각 URI에 대해 실제 데이터 GET\n",
        "    for idx, uri in enumerate(uri_list, start=1):\n",
        "        print(f\"    [FETCH {idx}/{total_uris}] {uri}\")\n",
        "        retries = 0\n",
        "        while retries < max_retries:\n",
        "            cin = http_get(base_path + uri, iotPlatform=True)\n",
        "            if cin is not None:\n",
        "                con_list.append(cin[\"m2m:cin\"][\"con\"])\n",
        "                break\n",
        "            else:\n",
        "                retries += 1\n",
        "                print(f\"[Retry {retries}] for URL: {base_path + uri}\")\n",
        "\n",
        "        if retries == max_retries:\n",
        "            print(f\"[FAIL] Data not fetched after {max_retries} attempts for URL: {base_path + uri}\")\n",
        "\n",
        "    return con_list\n",
        "\n",
        "\n",
        "def upload_data(container_name, data, base_url):\n",
        "    \"\"\"\n",
        "    컨테이너에 데이터(CIN) 업로드\n",
        "    \"\"\"\n",
        "    url = f\"{base_url}/{container_name}\"\n",
        "    body = {\n",
        "        \"m2m:cin\": {\n",
        "            \"con\": data\n",
        "        }\n",
        "    }\n",
        "    response = requests.post(url, headers=HEADERS_CIN, json=body)\n",
        "    if response.status_code in [200, 201]:\n",
        "        print(f\"[OK] 업로드 성공: {container_name}\")\n",
        "    else:\n",
        "        print(f\"[FAIL] 업로드 실패: {response.text}\")\n",
        "        \n",
        "\n",
        "def decode_model(base64_str, save_path=\"./mnist_cnn.pth\"):\n",
        "    \"\"\"\n",
        "    - Base64 문자열을 받아 .pth 모델 파일로 저장\n",
        "    - 저장 경로 반환\n",
        "    \"\"\"\n",
        "    decoded_bytes = base64.b64decode(base64_str)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        f.write(decoded_bytes)\n",
        "    return save_path\n",
        "# --------------------------------------------------------------------------------\n",
        "# (3) 모델 정의 (예: MNISTCNN)\n",
        "# --------------------------------------------------------------------------------\n",
        "class MNISTCNN(nn.Module):\n",
        "    def __init__(self, output_size=10):\n",
        "        super(MNISTCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1   = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2   = nn.Linear(128, output_size)\n",
        "        self.pool  = nn.MaxPool2d(2, 2)\n",
        "        self.relu  = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# (4) 이미지 전처리 함수 (Base64 → 텐서)\n",
        "# --------------------------------------------------------------------------------\n",
        "def preprocess_image_bytes(b64_str):\n",
        "    \"\"\"\n",
        "    - Base64 문자열(b64_str)을 받아,\n",
        "      1) base64 디코딩 → 2) BytesIO → 3) PIL.Image\n",
        "      4) 28×28 흑백으로 변환 → 5) NumPy → 6) PyTorch 텐서\n",
        "    - 최종 shape: (1, 1, 28, 28)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1) base64 → bytes\n",
        "        img_bytes = base64.b64decode(b64_str)\n",
        "        # 2) BytesIO → PIL\n",
        "        pil_image = Image.open(BytesIO(img_bytes)).convert(\"L\")\n",
        "        # 3) 28×28 리사이즈 (MNIST)\n",
        "        pil_image = pil_image.resize((28, 28))\n",
        "        # 4) [0~255] 범위 유지 (정규화 제거)\n",
        "        arr = np.array(pil_image).astype(np.float32)\n",
        "        # 5) (H, W) → (1, 1, H, W)\n",
        "        tensor = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)  # [1, 1, 28, 28]\n",
        "        return tensor\n",
        "    except Exception as e:\n",
        "        print(f\"[Error] preprocess_image_bytes failed: {e}\")\n",
        "        return None\n",
        "# --------------------------------------------------------------------------------\n",
        "# (5) 메인: Mobius 모델 로드 + 추론 후 결과 업로드 \n",
        "# --------------------------------------------------------------------------------       \n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1) Mobius에서 최신 모델 가져오기\n",
        "    model_repo_path = f\"{MOBIUS_DATA_AE_URL}/{MOBIUS_MODEL_REPOSITORY_CNT_NAME}\"\n",
        "    con_list = all_cin_get_uri(model_repo_path)\n",
        "    if not con_list:\n",
        "        print(\"[Error] No model data in Mobius.\")\n",
        "        exit(1)\n",
        "\n",
        "    # 1.1) 가장 최근에 올라온 모델(con_list[-1]) 사용\n",
        "    latest_model_data = con_list[-1] \n",
        "    base64_model_str  = latest_model_data[\"model_file\"]\n",
        "    metadata          = latest_model_data[\"metadata\"]\n",
        "\n",
        "    # 1.2) 디코딩 → 로컬에 저장\n",
        "    model_path = decode_model(base64_model_str, save_path=\"./mnist_cnn.pth\")\n",
        "\n",
        "    # 1.3) 모델 로드\n",
        "    model = MNISTCNN(output_size=10)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'), weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"[MODEL SERVER] Loaded model: {metadata['model_name']} (version {metadata['version']})\")\n",
        "\n",
        "    # 2) Mobius에서 이미지 데이터 가져오기\n",
        "    image_data_url = f\"{MOBIUS_DATA_AE_URL}/{MOBIUS_IMAGE_DATA_CNT_NAME}\"\n",
        "    image_con_list = all_cin_get_uri(image_data_url)\n",
        "\n",
        "    if not image_con_list:\n",
        "        print(\"[Error] No image data in Mobius.\")\n",
        "        exit(1)\n",
        "\n",
        "    print(f\"[OK] 이미지 {len(image_con_list)}개 로드 완료\")\n",
        "\n",
        "    # 3) 각 이미지에 대해 추론 수행 및 결과 업로드\n",
        "    for idx, con in enumerate(image_con_list, start=1):\n",
        "        # con 구조: {\"timestamp\": \"...\", \"raw_base64\": \"...\"}\n",
        "        b64_str = con.get(\"raw_base64\", \"\")\n",
        "        \n",
        "        if not b64_str:\n",
        "            print(f\"  [{idx}] 이미지 데이터 없음, 건너뜀\")\n",
        "            continue\n",
        "\n",
        "        # (3.1) 이미지 전처리\n",
        "        image_tensor = preprocess_image_bytes(b64_str)\n",
        "        if image_tensor is None:\n",
        "            continue\n",
        "\n",
        "        # (3.2) 추론\n",
        "        with torch.no_grad():\n",
        "            output = model(image_tensor)\n",
        "            pred = torch.argmax(output).item()\n",
        "\n",
        "        # (3.3) 추론 결과 생성\n",
        "        result_data = {\n",
        "            \"prediction\": pred,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # (3.4) 추론 결과를 Mobius의 inferencing_result 컨테이너에 업로드\n",
        "        upload_data(MOBIUS_STUDENT_INFERENCING_RESULT_CNT_NAME, result_data, MOBIUS_STUDENT_AE_URL)\n",
        "\n",
        "        print(f\"[INFERENCE] Image {idx}: Prediction = {pred}\")\n",
        "        \n",
        "        # 서버 처리 순서 보장을 위한 딜레이\n",
        "        time.sleep(1.0)\n",
        "\n",
        "    print(\"\\n[완료] 모든 이미지 추론 및 업로드 완료!\")\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "AIoT_class",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
